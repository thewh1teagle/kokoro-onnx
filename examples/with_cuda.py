"""
Note:
    On Linux you need to run this as well: apt-get install portaudio19-dev
    gpu version is sufficient only for Linux and Windows. macOS works with GPU by default.
    You can see the used execution provider by enable debug log. see with_log.py
    The script tested on CUDA 12.1 with CUDNN 9.1.0 on RTX4060 TI
    You might need to install the current CUDA version along with the CUDNN version (12.1, 9.1.0)
    See https://developer.nvidia.com/cuda-12-1-0-download-archive and https://developer.nvidia.com/cudnn-9-1-0-download-archive

Setup:
    pip install -U kokoro-onnx[gpu] soudfile
    wget https://github.com/thewh1teagle/kokoro-onnx/releases/download/model-files-v1.0/kokoro-v1.0.onnx
    wget https://github.com/thewh1teagle/kokoro-onnx/releases/download/model-files-v1.0/voices-v1.0.bin

Run with Python:
    python examples/with_cuda.py

Run with uv (if you cloned the repo):
    uv run --extra gpu ./examples/with_cuda.py 
"""

import soundfile as sf
from kokoro_onnx import Kokoro
import onnxruntime as ort
import os 


providers = ort.get_available_providers()  # List available providers
is_cuda = "CUDAExecutionProvider" in providers  # True if CUDA is among them
print("Available providers:", providers)  # Show all providers
print(f"Is CUDA available: {is_cuda}")  # Indicate if CUDA is available
os.environ["ONNX_PROVIDER"] = "CUDAExecutionProvider" if is_cuda else "CPUExecutionProvider" # In some envs you may need to force the Cuda provider for allocate the model on GPU

kokoro = Kokoro("kokoro-v1.0.onnx", "voices-v1.0.bin")
samples, sample_rate = kokoro.create(
    "Hello. This audio generated by kokoro!", voice="af_sarah", speed=1.0, lang="en-us"
)
sf.write('audio.wav', samples, sample_rate)
print('Created audio.wav')
